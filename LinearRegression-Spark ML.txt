spark-shell --master yarn --jars /home/cloudera/Downloads/commons-csv-1.5.jar,/home/cloudera/Downloads/spark-csv_2.10-1.5.0.jar

import org.apache.spark.sql.functions._
import org.apache.spark.ml.feature.{VectorAssembler}
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.regression.{LinearRegression}
import org.apache.spark.ml.tuning.{CrossValidator, CrossValidatorModel, ParamGridBuilder}
import org.apache.spark.ml.evaluation.{RegressionEvaluator}
import org.apache.spark.ml.param.ParamMap
import org.apache.spark.sql.types.{DoubleType}

import org.apache.spark.sql.SQLContext
val sqlContext = new SQLContext(sc)

val data_2015 = sqlContext.read.format("com.databricks.spark.csv")
.option("header", "true") 
.option("inferSchema", "true")
.load("hdfs://internal-ip:portno/BigData/happiness.csv")

val rank_score = data_2015.select(col("Happiness Rank").cast(DoubleType),col("GDP per capita").cast(DoubleType),col("Social support").cast(DoubleType),col("lowerwhisker").cast(DoubleType))

val Array(trainingData, testData) = rank_score.randomSplit(Array(0.8, 0.2), 1111) 

val assembler = new VectorAssembler()
.setInputCols(Array("GDP per capita"))
.setInputCols(Array("Social support"))
.setInputCols(Array("lowerwhisker"))
.setOutputCol("assembled-features")

val lr = new LinearRegression() 
 .setFeaturesCol("assembled-features")
 .setLabelCol("Happiness Rank")

val pipeline = new Pipeline()
 .setStages(Array(assembler, lr))

val evaluator = new RegressionEvaluator()
 .setLabelCol("Happiness Rank")
 .setPredictionCol("prediction")
 .setMetricName("r2")

val cross_validator = new CrossValidator()
 .setEstimator(pipeline)
 .setEvaluator(evaluator)
 .setEstimatorParamMaps(new ParamGridBuilder().build)
 .setNumFolds(3)

val cvModel = cross_validator.fit(trainingData)

val predictions = cvModel.transform(testData)

predictions
 .select(col("Happiness Rank"),col("GDP per capita"),col("Social support"),col("lowerwhisker"),col("prediction"))
 .write
 .format("csv")
 .save("hdfs://internal-ip:portno/BigData/happiness/output/")

val r2 = evaluator.evaluate(predictions)

println("r-squared on test data = " + r2)
